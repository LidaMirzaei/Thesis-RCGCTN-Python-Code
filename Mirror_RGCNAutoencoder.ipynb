{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16e4beb4-e2fa-441e-b495-abf6a0eacf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # NumPy for numerical operations\n",
    "import pandas as pd  # Pandas for data manipulation and analysis\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e865f68-70c6-49a9-8471-918bcf954352",
   "metadata": {},
   "source": [
    "#### Loading rating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ae6ce15-be47-4d91-9dc7-bfe80c91338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the MATLAB file path for ratings data of Epinion data set\n",
    "mat_file_path = 'Data/rating.mat'\n",
    "\n",
    "# Load the MATLAB file\n",
    "mat_data = loadmat(mat_file_path)\n",
    "\n",
    "# Assuming the MATLAB file contains a variable named 'ratings' for ratings data\n",
    "ratings_data = mat_data['rating']\n",
    "\n",
    "# Create a DataFrame from the ratings data\n",
    "ratings_df = pd.DataFrame(ratings_data, columns=['user_id', 'item_id', 'cat_id', 'rating'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be68423-4a5f-4123-b7c5-713ad821aac0",
   "metadata": {},
   "source": [
    "#### Loading trust relationship data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "181aad53-56f1-4270-a2c0-5b122b475cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the relationships file path of Epinion data set\n",
    "trust_path = 'Data/epinions.txt'\n",
    "\n",
    "# Define the column names for the trust dataset\n",
    "columns = [\"trustor_id\", \"trustee_id\", \"trust_label\"]\n",
    "\n",
    "# Read the trust dataset from the specified file\n",
    "trust_df = pd.read_csv(trust_path, sep='\\t', header=None, names=columns, skiprows=1, skipfooter=1, engine='python')\n",
    "\n",
    "# Replace trust labels {-1, 1} with {0, 1}\n",
    "trust_df['trust_label'] = trust_df['trust_label'].replace({-1: 0})\n",
    "\n",
    "# Drop rows where trustee ids are greater than 22166 in the original DataFrame\n",
    "trust_df.drop(trust_df[trust_df['trustee_id'] > max(ratings_df['user_id'])].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc612978-51b6-4159-81ff-1e6d640df1a2",
   "metadata": {},
   "source": [
    "#### Specifying unique ids in the rating data and trust data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a333f128-cba1-41b7-b92f-4849119f26f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique number of user IDs: 22164\n",
      "Unique number of item IDs: 296277\n",
      "Unique number of trustor IDs: 1819\n",
      "Unique number of trustee IDs: 8873\n"
     ]
    }
   ],
   "source": [
    "# Count unique user IDs in the ratings dataset\n",
    "unique_user_count = ratings_df['user_id'].nunique()\n",
    "print(\"Unique number of user IDs:\", unique_user_count)\n",
    "\n",
    "# Count unique item IDs in the ratings dataset\n",
    "unique_item_count = ratings_df['item_id'].nunique()\n",
    "print(\"Unique number of item IDs:\", unique_item_count)\n",
    "\n",
    "# Count unique trustor IDs in the trust dataset\n",
    "unique_trustor_count = trust_df['trustor_id'].nunique()\n",
    "print(\"Unique number of trustor IDs:\", unique_trustor_count)\n",
    "\n",
    "# Count unique trustee IDs in the trust dataset\n",
    "unique_trustee_count = trust_df['trustee_id'].nunique()\n",
    "print(\"Unique number of trustee IDs:\", unique_trustee_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df26ada9-4372-470a-a176-e6b001a0c9d2",
   "metadata": {},
   "source": [
    "#### Calculating link conection similarity and item similarity as attributes (features) between nodes (trustors and trustees, for trust relations)\n",
    "***using Jaccard and Adamic-Adar index***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a73c9cfe-1916-497a-ba7a-424fdbd0a1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        trustor_id  trustee_id  item_similarity\n",
      "1                2           3              0.0\n",
      "2                4           5              0.0\n",
      "3                4         155              0.0\n",
      "4                4         558              0.0\n",
      "5                4        1509              0.0\n",
      "...            ...         ...              ...\n",
      "105055        2010       16147              0.0\n",
      "105056        2010       16212              0.0\n",
      "105057        2010       16331              0.0\n",
      "105058        2010       16608              0.0\n",
      "105059        2010       16639              0.0\n",
      "\n",
      "[71407 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define a function to calculate Jaccard similarity between two sets\n",
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0.0\n",
    "\n",
    "# set the rated items for each user\n",
    "user_item_sets = ratings_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "\n",
    "# Create an empty list to store Jaccard similarities\n",
    "item_similarities = []\n",
    "\n",
    "for index, row in trust_df.iterrows():\n",
    "    trustor_id = row['trustor_id']\n",
    "    trustee_id = row['trustee_id']\n",
    "\n",
    "    # Get sets of rated items for trustor and trustee\n",
    "    trustor_items = user_item_sets.get(trustor_id, set())\n",
    "    trustee_items = user_item_sets.get(trustee_id, set())\n",
    "\n",
    "    # Calculate Jaccard similarity based on commen rated items\n",
    "    similarity = jaccard_similarity(trustor_items, trustee_items)\n",
    "    item_similarities.append(similarity)\n",
    "\n",
    "# Add the calculated Adamic-Adar scores to the trust dataframe\n",
    "trust_df['item_similarity'] = item_similarities\n",
    "\n",
    "# Print the trust dataframe with the new column\n",
    "print(trust_df[['trustor_id', 'trustee_id', 'item_similarity']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a39b1597-e7c0-4da6-bdda-711c744a68f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        trustor_id  trustee_id  link_similarity\n",
      "1                2           3         0.000000\n",
      "2                4           5         0.169892\n",
      "3                4         155         0.659386\n",
      "4                4         558         0.194269\n",
      "5                4        1509         0.238683\n",
      "...            ...         ...              ...\n",
      "105055        2010       16147         0.000000\n",
      "105056        2010       16212         0.180337\n",
      "105057        2010       16331         3.324407\n",
      "105058        2010       16608         0.865039\n",
      "105059        2010       16639         1.500470\n",
      "\n",
      "[71407 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from math import log\n",
    "\n",
    "# Create a graph from the trust dataframe\n",
    "G = nx.from_pandas_edgelist(trust_df, 'trustor_id', 'trustee_id')\n",
    "\n",
    "# Calculate Adamic-Adar index for each trust relationship\n",
    "adamic_adar_scores = []\n",
    "for index, row in trust_df.iterrows():\n",
    "    trustor_id = row['trustor_id']\n",
    "    trustee_id = row['trustee_id']\n",
    "\n",
    "    # Get common neighbors\n",
    "    common_neighbors = list(nx.common_neighbors(G, trustor_id, trustee_id))\n",
    "\n",
    "    # Calculate Adamic-Adar index\n",
    "    adamic_adar_index = sum(1 / (log(G.degree(neighbor)) if G.degree(neighbor) > 1 else 1) for neighbor in common_neighbors)\n",
    "\n",
    "    # Append the calculated index to the list\n",
    "    adamic_adar_scores.append(adamic_adar_index)\n",
    "\n",
    "# Add the calculated Adamic-Adar scores to the trust dataframe\n",
    "trust_df['link_similarity'] = adamic_adar_scores\n",
    "\n",
    "# Print the trust dataframe with the new column\n",
    "print(trust_df[['trustor_id', 'trustee_id', 'link_similarity']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462d79d4-0792-4dc8-ad94-a4607c237b88",
   "metadata": {},
   "source": [
    "#### Information Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39b14a6e-243c-4440-9535-b941052c0094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        trustor_id  trustee_id  aggregated_similarity\n",
      "1                2           3               0.569635\n",
      "2                4           5               0.510490\n",
      "3                4         155               0.226366\n",
      "4                4         558               0.941081\n",
      "5                4        1509               0.789434\n",
      "...            ...         ...                    ...\n",
      "105055        2010       16147               0.751806\n",
      "105056        2010       16212               0.372993\n",
      "105057        2010       16331               0.492481\n",
      "105058        2010       16608               0.888731\n",
      "105059        2010       16639               0.065910\n",
      "\n",
      "[71407 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate a random weight matrix with values between 0 and 1\n",
    "random_weight_matrix = np.random.rand(trust_df.shape[0], 1)\n",
    "\n",
    "# Combine matrices using horizontal stacking\n",
    "aggregated_matrix = np.hstack([trust_df['item_similarity'].values.reshape(-1, 1), \n",
    "                               trust_df['link_similarity'].values.reshape(-1, 1), \n",
    "                               random_weight_matrix])\n",
    "\n",
    "trust_df['aggregated_similarity'] = aggregated_matrix[:, 2]\n",
    "\n",
    "# Print the trust dataframe with the new column\n",
    "print(trust_df[['trustor_id', 'trustee_id', 'aggregated_similarity']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc3e190f-65b9-4b5e-810d-f00e25541438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustor_id</th>\n",
       "      <th>trustee_id</th>\n",
       "      <th>trust_label</th>\n",
       "      <th>item_similarity</th>\n",
       "      <th>link_similarity</th>\n",
       "      <th>aggregated_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.074927</td>\n",
       "      <td>-0.599191</td>\n",
       "      <td>0.240671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.074927</td>\n",
       "      <td>-0.571375</td>\n",
       "      <td>0.035448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.074927</td>\n",
       "      <td>-0.491233</td>\n",
       "      <td>-0.950400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>558</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.074927</td>\n",
       "      <td>-0.567384</td>\n",
       "      <td>1.529510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>1509</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.074927</td>\n",
       "      <td>-0.560113</td>\n",
       "      <td>1.003327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105055</th>\n",
       "      <td>2010</td>\n",
       "      <td>16147</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.074927</td>\n",
       "      <td>-0.599191</td>\n",
       "      <td>0.872767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105056</th>\n",
       "      <td>2010</td>\n",
       "      <td>16212</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.074927</td>\n",
       "      <td>-0.569665</td>\n",
       "      <td>-0.441636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105057</th>\n",
       "      <td>2010</td>\n",
       "      <td>16331</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.074927</td>\n",
       "      <td>-0.054902</td>\n",
       "      <td>-0.027037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105058</th>\n",
       "      <td>2010</td>\n",
       "      <td>16608</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.074927</td>\n",
       "      <td>-0.457562</td>\n",
       "      <td>1.347866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105059</th>\n",
       "      <td>2010</td>\n",
       "      <td>16639</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.074927</td>\n",
       "      <td>-0.353526</td>\n",
       "      <td>-1.507150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71407 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        trustor_id  trustee_id  trust_label  item_similarity  link_similarity  \\\n",
       "1                2           3            1        -0.074927        -0.599191   \n",
       "2                4           5            0        -0.074927        -0.571375   \n",
       "3                4         155            0        -0.074927        -0.491233   \n",
       "4                4         558            1        -0.074927        -0.567384   \n",
       "5                4        1509            0        -0.074927        -0.560113   \n",
       "...            ...         ...          ...              ...              ...   \n",
       "105055        2010       16147            1        -0.074927        -0.599191   \n",
       "105056        2010       16212            1        -0.074927        -0.569665   \n",
       "105057        2010       16331            1        -0.074927        -0.054902   \n",
       "105058        2010       16608            0        -0.074927        -0.457562   \n",
       "105059        2010       16639            1        -0.074927        -0.353526   \n",
       "\n",
       "        aggregated_similarity  \n",
       "1                    0.240671  \n",
       "2                    0.035448  \n",
       "3                   -0.950400  \n",
       "4                    1.529510  \n",
       "5                    1.003327  \n",
       "...                       ...  \n",
       "105055               0.872767  \n",
       "105056              -0.441636  \n",
       "105057              -0.027037  \n",
       "105058               1.347866  \n",
       "105059              -1.507150  \n",
       "\n",
       "[71407 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Normalizing features\n",
    "\n",
    "features_to_normalize = trust_df[['item_similarity', 'link_similarity', 'aggregated_similarity']]\n",
    "\n",
    "# Calculate mean and std\n",
    "mean = features_to_normalize.mean()\n",
    "std = features_to_normalize.std()\n",
    "\n",
    "# Normalize the features\n",
    "normalized_features = (features_to_normalize - mean) / std\n",
    "\n",
    "# Update the original DataFrame with normalized values\n",
    "trust_df[['item_similarity', 'link_similarity', 'aggregated_similarity']] = normalized_features\n",
    "\n",
    "trust_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55da9fc-be4c-4f07-b1ba-6e727f4f4c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e67c00cb-eb05-4df6-bf17-10ba000974c4",
   "metadata": {},
   "source": [
    "#### Develop Mirror to predict trust relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6faaf789-13c7-429a-ad87-44a4848ee58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing PyTorch and PyG modules, and the necessary libraries for this end\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import ChebConv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b44ff365-38be-4290-9116-ddb4c4884c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' # defines the MIRROR model using the RGCNConv (Relational Graph Convolutional Network Convolution) layer \n",
    "      for a relational graph classification task with Autoencoder.'''\n",
    "\n",
    "# Define the autoencoder model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Linear(input_dim, hidden_dim)\n",
    "        self.decoder = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = F.relu(self.encoder(x))\n",
    "        decoded = torch.sigmoid(self.decoder(encoded))\n",
    "        return encoded, decoded\n",
    "\n",
    "# Define the TrustRGCNAutoencoder model with the autoencoder\n",
    "class TrustRGCNAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim_ae, hidden_dim_rgcn, output_dim, num_relations, num_bases):\n",
    "        super(TrustRGCNAutoencoder, self).__init__()\n",
    "        self.autoencoder = Autoencoder(input_dim, hidden_dim_ae)\n",
    "        self.rgcn1 = ChebConv(hidden_dim_ae, hidden_dim_rgcn, K=2, normalization='sym')\n",
    "        self.rgcn2 = ChebConv(hidden_dim_rgcn, hidden_dim_rgcn, K=2, normalization='sym')\n",
    "        self.linear = nn.Linear(hidden_dim_rgcn, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_type = data.x, data.edge_index, data.edge_type\n",
    "        encoded, _ = self.autoencoder(x)  # Use only the encoded features\n",
    "        x = F.relu(self.rgcn1(encoded, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.rgcn2(x, edge_index))\n",
    "        x = self.linear(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc0d9d57-5a63-48d3-a298-0acf63c290f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepares data for a PyTorch Geometric model\n",
    "\n",
    "# Assuming you have unique node IDs for trustors and trustees\n",
    "trustors = trust_df['trustor_id'].unique()\n",
    "trustees = trust_df['trustee_id'].unique()\n",
    "\n",
    "# Create a mapping of node IDs to indices\n",
    "node_to_index = {node: index for index, node in enumerate(set(trustors) | set(trustees))}\n",
    "\n",
    "# Map node IDs in the dataframe to indices\n",
    "trust_df['trustor_index'] = trust_df['trustor_id'].map(node_to_index)\n",
    "trust_df['trustee_index'] = trust_df['trustee_id'].map(node_to_index)\n",
    "\n",
    "# Manually create edge_index and edge_type\n",
    "trustor_indices = torch.tensor(trust_df['trustor_index'].values, dtype=torch.long)\n",
    "trustee_indices = torch.tensor(trust_df['trustee_index'].values, dtype=torch.long)\n",
    "edge_index = torch.stack([trustor_indices, trustee_indices], dim=0)\n",
    "edge_type = torch.tensor(trust_df['trust_label'].values, dtype=torch.long)\n",
    "\n",
    "# Features: Include similarity and any other relevant features\n",
    "# For simplicity, assuming only 'link_similarity' is a feature\n",
    "features = torch.tensor(trust_df[['item_similarity', 'link_similarity', 'aggregated_similarity']].values, dtype=torch.float)\n",
    "\n",
    "# Labels: Assuming 'trust_label' is the target variable\n",
    "labels = torch.tensor(trust_df['trust_label'].values, dtype=torch.long)\n",
    "\n",
    "# Create a torch_geometric Data object\n",
    "data = Data(x=features, edge_index=edge_index, y=labels, edge_type=edge_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2838e894-8147-479d-b492-37c0c2d6b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_data, test_data = train_test_split(trust_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create separate Data objects for training and testing\n",
    "train_features = torch.tensor(train_data[['item_similarity', 'link_similarity', 'aggregated_similarity']].values, dtype=torch.float).reshape(-1, 3)\n",
    "train_labels = torch.tensor(train_data['trust_label'].values, dtype=torch.long)\n",
    "train_edge_index = torch.stack(\n",
    "    [torch.tensor(train_data['trustor_index'].values, dtype=torch.long),\n",
    "     torch.tensor(train_data['trustee_index'].values, dtype=torch.long)],\n",
    "    dim=0\n",
    ")\n",
    "\n",
    "train_edge_type = torch.tensor(train_data['trust_label'].values, dtype=torch.long)\n",
    "train_data = Data(x=train_features, edge_index=train_edge_index, y=train_labels, edge_type=train_edge_type)\n",
    "\n",
    "test_features = torch.tensor(test_data[['item_similarity', 'link_similarity', 'aggregated_similarity']].values, dtype=torch.float).reshape(-1, 3)\n",
    "test_labels = torch.tensor(test_data['trust_label'].values, dtype=torch.long)\n",
    "test_edge_index = torch.stack(\n",
    "    [torch.tensor(test_data['trustor_index'].values, dtype=torch.long),\n",
    "     torch.tensor(test_data['trustee_index'].values, dtype=torch.long)],\n",
    "    dim=0\n",
    ")\n",
    "\n",
    "test_edge_type = torch.tensor(test_data['trust_label'].values, dtype=torch.long)\n",
    "test_data = Data(x=test_features, edge_index=test_edge_index, y=test_labels, edge_type=test_edge_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0f90a24-a714-41dc-a0ea-29bf9bf6abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TrustRGCNAutoencoder model\n",
    "input_dim_ae = features.shape[1]\n",
    "num_relations = len(trust_df['trust_label'].unique())\n",
    "output_dim = 1  # Binary classification (trust/distrust)\n",
    "hidden_dim_ae = 64  # Adjust based on your data\n",
    "hidden_dim_rgcn = 128  # Adjust based on your data\n",
    "model = TrustRGCNAutoencoder(input_dim_ae, hidden_dim_ae, hidden_dim_rgcn, output_dim, num_relations, num_bases=2)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9656138-961b-420f-8e73-6ab4956b7fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6968045830726624\n",
      "Epoch 10, Loss: 0.47611555457115173\n",
      "Epoch 20, Loss: 0.46949368715286255\n",
      "Epoch 30, Loss: 0.4663015604019165\n",
      "Epoch 40, Loss: 0.46648508310317993\n",
      "Epoch 50, Loss: 0.4654458463191986\n",
      "Epoch 60, Loss: 0.4646461606025696\n",
      "Epoch 70, Loss: 0.4638225734233856\n",
      "Epoch 80, Loss: 0.4640229642391205\n",
      "Epoch 90, Loss: 0.4634787440299988\n",
      "Epoch 100, Loss: 0.46297934651374817\n",
      "Epoch 110, Loss: 0.463005006313324\n",
      "Epoch 120, Loss: 0.4628426432609558\n",
      "Epoch 130, Loss: 0.46257176995277405\n",
      "Epoch 140, Loss: 0.4624241590499878\n",
      "Epoch 150, Loss: 0.46243277192115784\n",
      "Epoch 160, Loss: 0.46262502670288086\n",
      "Epoch 170, Loss: 0.46221575140953064\n",
      "Epoch 180, Loss: 0.46217212080955505\n",
      "Epoch 190, Loss: 0.4621158242225647\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(train_data)\n",
    "    \n",
    "    # Modify target to match the output shape\n",
    "    target = train_data.y.float().view(-1, 1)\n",
    "    \n",
    "    loss = criterion(out, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print training loss for monitoring\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b82f04d9-32aa-4e4e-a76a-af9142630bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8227839238201933\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(test_data)\n",
    "\n",
    "# Apply sigmoid to get probability scores\n",
    "probabilities = torch.sigmoid(pred)\n",
    "\n",
    "# Compute metrics\n",
    "predicted_labels = ((probabilities) > 0.5) # 0.5 is the threshold\n",
    "accuracy = accuracy_score(test_labels.numpy(), predicted_labels.numpy())\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b0d16-d0c8-41df-8107-2f74df6e0c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84cd06d-0427-4ecb-bbdf-4b6c57012182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec4b0bc-d034-442d-b254-b18f8417b8b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
