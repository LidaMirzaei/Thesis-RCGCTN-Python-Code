{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "467cf4b0-6f02-4f61-8cd8-1702f2317d11",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa16ef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f71248",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24096196",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf7fb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60c203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # NumPy for numerical operations\n",
    "import pandas as pd  # Pandas for data manipulation and analysis\n",
    "import tensorflow as tf # TensorFlow for machine learning\n",
    "from sklearn.preprocessing import StandardScaler  # Class for feature scaling\n",
    "import math  # Python math module for mathematical functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa14991-7447-4721-92de-39c5e52b99be",
   "metadata": {},
   "source": [
    "# Step 1: Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a085d479-2c3f-4955-ae3d-abbd1103bf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file paths for the rating and trust datasets\n",
    "rating_path = 'Data/ratings.txt'\n",
    "trust_path = 'Data/trust.txt'\n",
    "\n",
    "# Define the column names for the ratings dataset\n",
    "rating_columns = ['user_id', 'item_id', 'rating']\n",
    "\n",
    "# Read the ratings dataset from the specified file, using space (' ') as the separator\n",
    "ratings_df = pd.read_csv(rating_path, sep=' ', header=None, names=rating_columns)\n",
    "\n",
    "# Define the column names for the trust dataset\n",
    "trust_columns = ['trustor_id', 'trustee_id', 'trust_label']\n",
    "\n",
    "# Read the trust dataset from the specified file, using space (' ') as the separator\n",
    "trust_df = pd.read_csv(trust_path, sep=' ', header=None, names=trust_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb6040f-3dc4-45f2-ac1e-a8cdcd6166d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f9f452-279a-4ce5-9ac6-3b8660ca6c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f1aa01-82dc-42ce-a200-1a514e34205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trust_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56fd3fe-2eb5-4ef9-8734-a135f7c68cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4dd98f7-0785-4ffc-a285-d1c14401c272",
   "metadata": {},
   "source": [
    "## Insights into the uniqueness of IDs in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abfd9e0-6424-411c-afc8-d3bf99ef4aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique user IDs in the ratings dataset\n",
    "unique_user_count = ratings_df['user_id'].nunique()\n",
    "print(\"Unique number of user IDs:\", unique_user_count)\n",
    "\n",
    "# Count unique item IDs in the ratings dataset\n",
    "unique_item_count = ratings_df['item_id'].nunique()\n",
    "print(\"Unique number of item IDs:\", unique_item_count)\n",
    "\n",
    "# Count unique trustor IDs in the trust dataset\n",
    "unique_trustor_count = trust_df['trustor_id'].nunique()\n",
    "print(\"Unique number of trustor IDs:\", unique_trustor_count)\n",
    "\n",
    "# Count unique trustee IDs in the trust dataset\n",
    "unique_trustee_count = trust_df['trustee_id'].nunique()\n",
    "print(\"Unique number of trustee IDs:\", unique_trustee_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5104b6-0456-4615-ac73-f93d7c3c8dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab35059b-6d8d-4b61-9125-a48d76e2622d",
   "metadata": {},
   "source": [
    "## Creating rating matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d8942-6e72-452f-9224-ea5a35312b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate entries based on 'user_id' and 'item_id'\n",
    "duplicates = ratings_df.duplicated(subset=['user_id', 'item_id'])\n",
    "\n",
    "# Print the duplicate entries\n",
    "print(\"Duplicate entries:\\n\", ratings_df[duplicates])\n",
    "\n",
    "# Remove duplicate entries\n",
    "ratings_df = ratings_df.drop_duplicates(subset=['user_id', 'item_id'])\n",
    "\n",
    "# Pivot the DataFrame to create a ratings matrix\n",
    "ratings_matrix = ratings_df.pivot(index='user_id', columns='item_id', values='rating')\n",
    "\n",
    "# Fill NaN values with 0 if needed\n",
    "ratings_matrix = ratings_matrix.fillna(0)\n",
    "\n",
    "# Display the resulting ratings matrix\n",
    "ratings_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a8f560-3b91-4e97-9ad9-354290cccfa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02014d41-46db-48af-88d9-7355cc01c658",
   "metadata": {},
   "source": [
    "## Creating trust matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b4945a-ac98-4496-9031-e652bd5aed24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate entries based on 'trustor_id' and 'trustee_id'\n",
    "duplicates = trust_df.duplicated(subset=['trustor_id', 'trustee_id'])\n",
    "\n",
    "# Print the duplicate entries\n",
    "print(\"Duplicate entries:\\n\", trust_df[duplicates])\n",
    "\n",
    "# Remove duplicate entries\n",
    "trust_df = trust_df.drop_duplicates(subset=['trustor_id', 'trustee_id'])\n",
    "\n",
    "# Pivot the DataFrame to create a trust matrix\n",
    "trust_matrix = trust_df.pivot(index='trustor_id', columns='trustee_id', values='trust_label')\n",
    "\n",
    "# Fill NaN values with 0 if needed\n",
    "trust_matrix = trust_matrix.fillna(0)\n",
    "\n",
    "# Display the resulting trust matrix\n",
    "trust_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a556625-5c46-4f89-b608-9405d74f79ce",
   "metadata": {},
   "source": [
    "### Creating a full trust matrix with a specified size and updating its values based on an existing trust matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b4cd48-bf83-4c90-b778-3d93856ff0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty full_trust_matrix with size 1508x1508\n",
    "full_trust_matrix = pd.DataFrame(index=range(1, unique_user_count + 1), columns=range(1, unique_user_count + 1))\n",
    "\n",
    "# Update the values in full_trust_matrix based on trust_matrix\n",
    "for trustor_id in trust_matrix.index:\n",
    "    if trustor_id in range(1, unique_user_count):\n",
    "        \n",
    "        for trustee_id in trust_matrix.columns:\n",
    "            if trustee_id in range(1, unique_user_count):\n",
    "                \n",
    "                full_trust_matrix.at[trustor_id, trustee_id] = trust_matrix.at[trustor_id, trustee_id]\n",
    "\n",
    "# Convert the filled values to 0 where NaN (indicating missing values)\n",
    "full_trust_matrix.fillna(0, inplace=True)\n",
    "\n",
    "# Optionally, convert the DataFrame to a NumPy array if needed\n",
    "#full_trust_matrix_array = full_trust_matrix.to_numpy()\n",
    "\n",
    "# Display or use the filled full_trust_matrix\n",
    "full_trust_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd2f91-022a-4672-889e-c70d5a17b2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a481d63e-3a62-4d86-9616-de1dd3860c66",
   "metadata": {},
   "source": [
    "# Step 2: Information Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a26914-534f-4ed3-80ef-3af7fa618110",
   "metadata": {},
   "source": [
    "### Calculating Jaccard similarity based on users' rating matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bda8fb-1ed5-468a-b2a2-aac90432b737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binary matrix where 1 indicates a positive rating and 0 indicates no rating\n",
    "binary_ratings = ((ratings_matrix > 0).astype(int)).values\n",
    "\n",
    "# the Jaccard similarity function\n",
    "def jaccard_similarity(matrix):\n",
    "    num_users = matrix.shape[0]\n",
    "    jaccard_matrix = np.zeros((num_users, num_users))\n",
    "\n",
    "    for i in range(num_users):\n",
    "        for j in range(i + 1, num_users):\n",
    "            intersection = np.sum(np.logical_and(matrix[i, :], matrix[j, :]))\n",
    "            union = np.sum(np.logical_or(matrix[i, :], matrix[j, :]))\n",
    "\n",
    "            # Avoid division by zero\n",
    "            if union == 0:\n",
    "                jaccard_matrix[i, j] = 0\n",
    "            else:\n",
    "                jaccard_matrix[i, j] = intersection / union\n",
    "\n",
    "            # Since the matrix is symmetric, we can fill in the values on the other side of the diagonal\n",
    "            jaccard_matrix[j, i] = jaccard_matrix[i, j]\n",
    "\n",
    "    return jaccard_matrix\n",
    "\n",
    "# Calculate Jaccard similarity matrix using its function\n",
    "jaccard_matrix = jaccard_similarity(binary_ratings)\n",
    "\n",
    "# Print the Jaccard similarity matrix\n",
    "print(\"Jaccard Similarity Matrix:\")\n",
    "print(jaccard_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdea022-8509-40e6-b8a9-4098bcfb071b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9a5d82a-62fd-4b58-8def-2602cbf12430",
   "metadata": {},
   "source": [
    "### Calculating the Adamic-Adar similarity measure for trustors based on a binary trust matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29b9b9e-7076-4cd3-8591-a5c7acec15b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adamic_adar_for_trustors(matrix, trustor1, trustor2):\n",
    "    # Find neighbors of trustor1 and trustor2\n",
    "    neighbors1 = set(np.where(matrix[trustor1] == 1)[0])\n",
    "    neighbors2 = set(np.where(matrix[trustor2] == 1)[0])\n",
    "    \n",
    "    # Find common neighbors\n",
    "    common_neighbors = neighbors1.intersection(neighbors2)\n",
    "    \n",
    "    # Calculate Adamic-Adar similarity\n",
    "    adamic_adar = 0\n",
    "    for common_neighbor in common_neighbors:\n",
    "        trustor_degree = np.sum(matrix[:, common_neighbor])\n",
    "        adamic_adar += 1 / math.log(trustor_degree) if trustor_degree > 1 else 0\n",
    "    \n",
    "    return adamic_adar\n",
    "\n",
    "def calculate_adamic_adar_for_all_users(matrix):\n",
    "    num_users = matrix.shape[0]\n",
    "    adamic_adar_matrix = np.zeros((num_users, num_users))\n",
    "\n",
    "    for i in range(num_users):\n",
    "        for j in range(i + 1, num_users):\n",
    "            # Calculate Adamic-Adar similarity for each pair of trustors\n",
    "            adamic_adar_matrix[i, j] = adamic_adar_for_trustors(matrix, i, j)\n",
    "            adamic_adar_matrix[j, i] = adamic_adar_matrix[i, j]\n",
    "\n",
    "    return adamic_adar_matrix\n",
    "\n",
    "# Coverting 'trust_matrix' into a numpy array\n",
    "trust_matrix_np = np.array(full_trust_matrix)\n",
    "\n",
    "# Calculate Adamic-Adar Similarity Matrix for Users\n",
    "adamic_adar_matrix = calculate_adamic_adar_for_all_users(trust_matrix_np)\n",
    "\n",
    "# Print the Adamic-Adar Similarity Matrix\n",
    "print(\"Adamic-Adar Similarity Matrix for Users:\")\n",
    "print(adamic_adar_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c11a93-e5f0-49e7-9cb9-6bd9a209461d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c999d1de-2f5e-4b7a-a4c9-e11f70232fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75c69b0e-d515-4dba-b731-88414ba2e6d5",
   "metadata": {},
   "source": [
    "## Aggregating the Adamic-Adar Similarity and the Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6755a90e-06c6-4677-91e9-c5d3a2ca05f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random weight matrix with values between 0 and 1\n",
    "random_weight_matrix = np.random.rand(unique_user_count, unique_user_count)\n",
    "\n",
    "# Combine matrices using element-wise multiplication\n",
    "H_information = (jaccard_matrix + adamic_adar_matrix) * random_weight_matrix\n",
    "\n",
    "# Print the resulting matrix\n",
    "print(H_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e017e0-4c94-4363-89ec-4c909bb4a93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69989239-0450-461d-9a3d-81d47e0567ec",
   "metadata": {},
   "source": [
    "# Step 3: Bulding the Graph Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66b29e8-ffa7-4a4f-bb67-f1f4608877a9",
   "metadata": {},
   "source": [
    "### Define the Mirror model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fc6f5c-63a7-44d8-bf72-264186f2554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the Mirror model\n",
    "class MirrorModel(tf.keras.Model):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MirrorModel, self).__init__()\n",
    "        self.dense1 = layers.Dense(128, activation='relu', input_dim=input_dim)\n",
    "        self.dense2 = layers.Dense(output_dim, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        output = self.dense2(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f066793-9357-46a7-b740-adba84ae02ba",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf3ef37-0304-4540-94ef-8cf0f9268a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  # Function for splitting dataset\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(H_information, full_trust_matrix, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27717df9-df09-4a2e-8ac1-3826378511c9",
   "metadata": {},
   "source": [
    "### Instantiating and Compilling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e889da5b-55c3-49dc-a318-dec4de402227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming H_information.shape[1] is the number of features (user correlations)\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "# Assuming full_trust_matrix.shape[1] is the number of output nodes (users for whom trust is predicted)\n",
    "num_users = y_train.shape[1]\n",
    "\n",
    "# Instantiate the Mirror model\n",
    "mirror_model = MirrorModel(input_dim=num_features, output_dim=num_users)\n",
    "\n",
    "# Compile the model\n",
    "mirror_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9896554c-18cd-4f66-a7e8-fb3b29f49b01",
   "metadata": {},
   "source": [
    "### Train the Mirror model and Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b05078-b645-4923-953b-1f2d3d178129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Mirror model\n",
    "mirror_model.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.3)\n",
    "\n",
    "# Predicting by the Mirror model\n",
    "y_pred = mirror_model.predict(X_test) # y_pred contains predicted scores or probabilities\n",
    "y_pred_binary = (y_pred >= 0.3).astype(int)  # Thresholding at 0.5 for binary predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b599e-c152-4df8-8206-af404da60e03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fe49bdc-313b-4353-a50b-4a7c3aab7299",
   "metadata": {},
   "source": [
    "# Step 4: Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b97905a-797c-49d6-8e0c-793da6cf995c",
   "metadata": {},
   "source": [
    "### Measuring the Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e870de-7937-49a6-b45a-b787e7016680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score  # Function for evaluating model performance by accuracy\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "\n",
    "print(\"Accuracy:\", accuracy * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60306913-6dca-4080-8d28-6968226009e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbc30f23-035c-4692-877c-bcb6c5b9264f",
   "metadata": {},
   "source": [
    "### Calculating the Rank-Score (RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa0dc4d-3929-4b29-a6f0-13d9ac150731",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rank(edge, y_pred_row):\n",
    "    # Placeholder for your ranking function based on predicted probabilities or other criterion\n",
    "    # Replace this function with your actual implementation\n",
    "    return np.argsort(y_pred_row)[::-1].tolist().index(edge) + 1\n",
    "\n",
    "def calculate_RS(y_test_np, y_pred_binary):\n",
    "    num_rows, num_edges = y_test_np.shape\n",
    "\n",
    "    RS_list = []\n",
    "    \n",
    "    for row_idx in range(num_rows):\n",
    "        U = set(range(num_edges))  # Assuming each element in y_test_np represents an edge\n",
    "        Ep = set([i for i, label in enumerate(y_test_np[row_idx]) if label == 1])  # Set of labeled links\n",
    "\n",
    "        if len(Ep) == 0:\n",
    "            RS = 0.0  # Handle division by zero\n",
    "        else:\n",
    "            RSe_list = [rank(e, y_pred_binary[row_idx]) / len(U - Ep) for e in Ep]\n",
    "            RS = np.mean(RSe_list)\n",
    "\n",
    "        RS_list.append(RS)\n",
    "\n",
    "    return np.mean(RS_list)\n",
    "\n",
    "\n",
    "# Converting \"y_test\" into a numpy array\n",
    "y_test_np = np.array(y_test)\n",
    "\n",
    "# Calculate RS\n",
    "RS_score = calculate_RS(y_test_np, y_pred_binary)\n",
    "\n",
    "# Print RS Score\n",
    "print(\"RS Score:\", RS_score * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be27604-1f71-4169-ae09-e7f706537d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "201eda48-6275-49b2-9085-88f66494cee3",
   "metadata": {},
   "source": [
    "### Calculating the Area Under Cruve (AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80d9de7-b2c9-44b0-8f8e-4f100c6cc263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# cast y_test_np and y_pred_binary to integer arrays before calculating the ROC AUC score\n",
    "y_test_np = y_test_np.astype(int)\n",
    "y_pred_binary = y_pred_binary.astype(int)\n",
    "\n",
    "# Flatten y_test_np and y_pred_binary if they are a multi-dimensional array or a nested list\n",
    "flat_y_test_np = y_test_np.flatten()\n",
    "flat_y_pred_binary = y_pred_binary.flatten()\n",
    "\n",
    "# Check if both classes are still present in flat_y_test_np\n",
    "unique_classes_flat_y_test = np.unique(flat_y_test_np)\n",
    "if len(unique_classes_flat_y_test) < 2:\n",
    "    print(\"Error: Both positive and negative classes are required for ROC AUC score calculation.\")\n",
    "else:\n",
    "    # Calculate AUC\n",
    "    auc_score = roc_auc_score(flat_y_test_np, flat_y_pred_binary)\n",
    "\n",
    "    # Print AUC Score\n",
    "    print(\"AUC Score:\", auc_score * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff86f85-1aee-42ec-abeb-1876b75d7563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c593c6-20a8-428c-9559-383f4566e969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
